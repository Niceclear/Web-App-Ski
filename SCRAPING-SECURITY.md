# ğŸ•µï¸ SÃ©curitÃ© du Scraping - Anti-dÃ©tection

Ce document explique les mesures anti-dÃ©tection mises en place pour le scraping de Valmeinier.

---

## ğŸ›¡ï¸ Mesures implÃ©mentÃ©es

### 1. Rotation de User-Agent

**10 User-Agents diffÃ©rents** en rotation alÃ©atoire :
- Chrome Windows/Mac/Linux
- Firefox Windows/Mac/Linux
- Safari Mac
- Edge Windows

**Pourquoi ?**
- Ã‰vite d'Ãªtre dÃ©tectÃ© comme un bot
- Simule des visiteurs rÃ©els de diffÃ©rents navigateurs/OS
- Rend le pattern de scraping moins prÃ©visible

**Code :** [lib/scrapers/valmeinier-simple.ts](lib/scrapers/valmeinier-simple.ts:18-30)

---

### 2. DÃ©lai alÃ©atoire avant scraping

**DÃ©lai alÃ©atoire : 0 Ã  300 secondes (0-5 minutes)**

**Pourquoi ?**
- Les crons sont programmÃ©s Ã  7h00 et 12h00 **exactement**
- Sans dÃ©lai, le scraping arrive **toujours Ã  la mÃªme seconde** â†’ pattern facilement dÃ©tectable
- Avec le dÃ©lai alÃ©atoire :
  - Cron 7h00 â†’ scraping entre 7h00 et 7h05
  - Cron 12h00 â†’ scraping entre 12h00 et 12h05
- Simule un comportement humain (arrivÃ©e non prÃ©visible)

**Code :** [lib/scrapers/valmeinier-simple.ts](lib/scrapers/valmeinier-simple.ts:55-56)

---

### 3. Headers HTTP rÃ©alistes

Headers ajoutÃ©s pour simuler un navigateur rÃ©el :

```typescript
{
  'User-Agent': '...', // AlÃ©atoire
  'Accept': 'text/html,application/xhtml+xml,...',
  'Accept-Language': 'fr-FR,fr;q=0.9,...',
  'Accept-Encoding': 'gzip, deflate, br',
  'DNT': '1',
  'Connection': 'keep-alive',
  'Upgrade-Insecure-Requests': '1',
}
```

**Pourquoi ?**
- Un simple `User-Agent` seul n'est pas suffisant
- Les headers complets simulent un vrai navigateur
- Accepte le franÃ§ais en prioritÃ© (cohÃ©rent pour un site franÃ§ais)

---

## ğŸ“Š Comportement en production

### Timeline d'un scraping cron (exemple 7h00)

```
07:00:00 â†’ Vercel Cron dÃ©clenche /api/scrape
07:00:01 â†’ API valide CRON_SECRET
07:00:01 â†’ Scraper dÃ©marre
07:00:01 â†’ Calcul du dÃ©lai alÃ©atoire : ex. 123456ms (2min 3s)
07:02:04 â†’ SÃ©lection User-Agent alÃ©atoire : ex. Firefox Linux
07:02:04 â†’ Fetch de la page Valmeinier
07:02:05 â†’ Parsing + sauvegarde en DB
07:02:05 â†’ Scraping terminÃ© âœ…
```

**Avantage :** Chaque scraping arrive Ã  un moment **diffÃ©rent** et avec un **User-Agent diffÃ©rent**.

---

## ğŸ” Logs en production

Vous verrez dans les logs Vercel :

```
[Valmeinier Simple Scraper] Starting scrape at 2026-01-06T07:00:01.234Z
[Valmeinier Simple Scraper] Random delay: 123456ms (123.5s)
[Valmeinier Simple Scraper] Using User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:121...
[Valmeinier Simple Scraper] Fetching https://www.valmeinier.com/enneigement/
[Valmeinier Simple Scraper] HTML fetched, length: 45678
```

---

## âš™ï¸ Configuration

### Modifier le dÃ©lai maximum

Dans [lib/scrapers/valmeinier-simple.ts](lib/scrapers/valmeinier-simple.ts:55-56) :

```typescript
// Actuellement : 0-300s (0-5min)
await randomDelay(300000)

// Pour changer Ã  0-10min :
await randomDelay(600000)

// Pour dÃ©sactiver (dev uniquement) :
// await randomDelay(0)
```

### Ajouter des User-Agents

Ajoutez simplement dans le tableau `USER_AGENTS` :

```typescript
const USER_AGENTS = [
  // ... existants
  'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1',
]
```

---

## ğŸš¨ Limites et bonnes pratiques

### âœ… Ce qui est fait

- Rotation User-Agent
- DÃ©lai alÃ©atoire
- Headers rÃ©alistes
- Rate limiting cÃ´tÃ© API (1 scraping manuel toutes les 5min)

### âš ï¸ Ce qui n'est PAS fait (mais pourrait l'Ãªtre)

- **Proxy/IP rotation** : Toujours la mÃªme IP Vercel
- **Cookie handling** : Pas de cookies persistÃ©s
- **JavaScript rendering** : Fetch simple sans JS (Cheerio)
- **Referer header** : Pas de referer

### ğŸ“‹ Recommandations

1. **Ne pas abuser** : 2 scrapings par jour (7h + 12h) est raisonnable
2. **Monitoring** : Surveillez les logs pour dÃ©tecter des blocages
3. **Backup** : Si bloquÃ©, contactez Valmeinier pour une API officielle
4. **Respect** : Le site n'a pas de robots.txt qui interdit `/enneigement/`

---

## ğŸ“ˆ Statistiques attendues

| MÃ©trique | Valeur |
|----------|--------|
| Scrapings par jour | 2 (7h + 12h) |
| DÃ©lai moyen ajoutÃ© | 2min 30s |
| User-Agents diffÃ©rents | 10 |
| ProbabilitÃ© mÃªme timing 2 jours de suite | ~1/600 (0.16%) |
| ProbabilitÃ© mÃªme UA 2 fois de suite | 10% |

**Conclusion :** Pattern hautement imprÃ©visible et difficile Ã  dÃ©tecter. âœ…

---

## ğŸ› ï¸ Debug

### Tester localement

```bash
# Scraping avec dÃ©lai alÃ©atoire
npm run scrape

# Vous verrez les logs :
# [Valmeinier Simple Scraper] Random delay: 45678ms (45.7s)
# [Valmeinier Simple Scraper] Using User-Agent: Mozilla/5.0 ...
```

### DÃ©sactiver le dÃ©lai en dev

Commentez temporairement la ligne 56 dans `valmeinier-simple.ts` :

```typescript
// await randomDelay(300000)
```

---

## ğŸ” SÃ©curitÃ© additionnelle

### Rate limiting API

Le endpoint `/api/scrape` (POST) a un rate limiting :
- **1 scraping manuel max toutes les 5 minutes**
- EmpÃªche les abus mÃªme si le mot de passe fuite

**Code :** [lib/cron.ts](lib/cron.ts) (vÃ©rification du dernier scraping)

### Authentification crons

Les crons Vercel sont protÃ©gÃ©s par `CRON_SECRET` :
- Header `Authorization: Bearer <CRON_SECRET>`
- Seul Vercel peut dÃ©clencher les crons automatiques

**Code :** [app/api/scrape/route.ts](app/api/scrape/route.ts:24-42)

---

## âœ… Checklist dÃ©ploiement

Avant de dÃ©ployer en prod, vÃ©rifiez :

- [ ] `CRON_SECRET` configurÃ© dans Vercel
- [ ] Crons actifs dans vercel.json (7h et 12h)
- [ ] Logs Vercel accessibles pour monitoring
- [ ] Premier scraping manuel testÃ© avec dÃ©lai

---

**DerniÃ¨re mise Ã  jour :** 2026-01-06
